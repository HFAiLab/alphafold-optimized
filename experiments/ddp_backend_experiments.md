# Alphafold训练中不同DDP Backend性能差异的进一步讨论

在Alphafold训练中一直存在着hfreduce带来的收益不显著的问题，对于这个现象我们在之前从Alphafold的模型结构特性角度进行了分析，指出了这可能是由于Alphafold“模型参数很少，但计算量很大”的特点导致的结果。不过这并不能完全解释这个问题，因此诚然我们已经发现从整体训练角度来说hfreduce带来的开销减少在绝对值上并不大，但在这里我们还是希望通过实验，细致分析在使用不同ddp backend时通信开销的变化。



由于Alphafold模型的通信开销无论与前向传播时间，反向传播时间还是迭代总耗时相比都太小了，我们很难在这些数值上看到显著的变化。为了尽量排除这些干扰，我们设计并进行了三组实验来直接对比通信开销的变化情况。实验的设定分别如下：

| 序号 | GPU数 | DDP Backend | 迭代次数 | 耗时统计对象                        | 特征裁切 |
| ---- | ----- | ----------- | -------- | ----------------------------------- | -------- |
| 1    | 1     | 无          | 200      | loss.backward()                     | 最大     |
| 2    | 128   | NCCL        | 200      | loss.backward()                     | 最大     |
| 3    | 128   | HFReduce    | 200      | loss.backward() + model.sync_grad() | 最大     |

我们希望通过多卡与单卡训练的耗时对比，来直接看到多卡通信带来的额外开销。因此，我们对三种训练方式测试了其200次迭代的平均Backward耗时。

其中，“特征裁切-最大”代表了对特征进行了尽可能大的裁切，目的是避免因特征处理导致多卡训练时部分GPU上的梯度同步长期处于等待梯度状态，影响结果准确性。使用HFReduce时由于梯度同步被单独拆出，因此需要将两个函数合并统计梯度计算+梯度同步总时间。

最终我们会得到三个实验下分别的平均backward时间。不考虑多卡时因数据处理进度不同产生的等待，那么多卡训练时的backward时间减去单卡训练的backward时间即可认为是多机多卡带来的额外通信开销。



实验结果如下：

| 序号 | GPU数 | DDP Backend | Backward平均耗时(秒) | 通信开销(秒) |
| ---- | ----- | ----------- | -------------------- | ------------ |
| 1    | 1     | 无          | 5.63                 | 无           |
| 2    | 128   | NCCL        | 6.03                 | 0.4          |
| 3    | 128   | HFReduce    | 5.91                 | **0.28**     |

此时从结果中清晰可见，在萤火二号上使用DDP训练时，选择HFReduce能够比NCCL节省30%的通信开销，这是一个非常可观的数字。考虑到Alphafold的实际参数量（92M）与BERT-base（110M）接近，我们与之前BERT类模型在HFReduce上进行实验的数据对比：

BERT-large（300M参数） 在同样128卡时使用HFReduce每次迭代获得的通信开销收益约为0.32s(数据来自GTC Presentation中汇报的结果)；BERT-base在128卡时每次迭代获得的通信开销收益为0.13s(数据来自HFReduce repo中汇报的结果)。

Alphafold的结果基本与BERT-base的结果接近，参数量为Alphafold 3倍左右的BERT-large减少的通信开销也大致为其三倍，因此可以认为验证了HFReduce在Alphafold上也能起到与其他模型相近的加速效果，只是由于通信开销并不是Alphafold训练时的主要开销，因此显得并不突出。

